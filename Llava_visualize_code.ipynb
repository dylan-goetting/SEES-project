{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ba16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy, math, pickle, json, os\n",
    "import bertviz, uuid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from transformers.image_transforms import (\n",
    "    convert_to_rgb,\n",
    "    get_resize_output_image_size,\n",
    "    resize,\n",
    "    center_crop)\n",
    "from transformers.image_utils import (\n",
    "    infer_channel_dimension_format,\n",
    "    to_numpy_array)\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from collections import Counter\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAD_NUM = 32\n",
    "HEAD_DIM = 128\n",
    "HIDDEN_DIM = HEAD_NUM * HEAD_DIM\n",
    "gpu = 5\n",
    "OUTPUT_DIR = \"output_images\"  # Directory to save images\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Setup CUDA\n",
    "# torch.set_default_device(\"cuda\")\n",
    "# torch.cuda.set_device(gpu)\n",
    "zero_tensor = torch.tensor([0.0]*4096)\n",
    "# Setup\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    low_cpu_mem_usage=True, \n",
    "    revision='a272c74',\n",
    ")\n",
    "model.eval()\n",
    "processor = AutoProcessor.from_pretrained(model_id, revision='a272c74')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922dc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_url = \"http://images.cocodataset.org/val2017/000000219578.jpg\"\n",
    "image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "prompt = \"USER: <image>\\nWhat is the color of the dog?\\nASSISTANT: The color of the dog is\"\n",
    "inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "outputs_probs = get_prob(outputs[\"logits\"][0][-1])\n",
    "outputs_probs_sort = torch.argsort(outputs_probs, descending=True)\n",
    "print([processor.decode(x) for x in outputs_probs_sort[:10]])\n",
    "print(outputs_probs_sort[:10].tolist())\n",
    "all_pos_layer_input, all_pos_layer_output, all_last_attn_subvalues, = transfer_output(outputs[2])\n",
    "print('finished transfer_output')\n",
    "final_var = torch.tensor(all_pos_layer_output[-1][-1]).pow(2).mean(-1, keepdim=True)\n",
    "\n",
    "resample = 3\n",
    "shortest_edge = 336\n",
    "crop_size = {\"height\": 336, \"width\": 336}\n",
    "image_convert = convert_to_rgb(image)\n",
    "image_numpy = to_numpy_array(image_convert)\n",
    "input_data_format = infer_channel_dimension_format(image_numpy)\n",
    "output_size = get_resize_output_image_size(image_numpy, size=336,\n",
    "            default_to_square=False, input_data_format=input_data_format)\n",
    "image_resize = resize(image_numpy, output_size, resample=resample, input_data_format=input_data_format)\n",
    "image_center_crop = center_crop(image_resize, size=(crop_size[\"height\"], crop_size[\"width\"]), input_data_format=input_data_format)\n",
    "\n",
    "# print(image_numpy.shape, image_resize.shape, image_center_crop.shape)\n",
    "# img1 = Image.fromarray(image_numpy)\n",
    "# img2 = Image.fromarray(image_resize)\n",
    "demo_img = image_center_crop\n",
    "\n",
    "predict_index = outputs_probs_sort[0].item()\n",
    "print(predict_index, processor.decode(predict_index))\n",
    "\n",
    "#head-level increase\n",
    "all_head_increase = []\n",
    "for test_layer in range(LAYER_NUM):\n",
    "    cur_layer_input = torch.tensor(all_pos_layer_input[test_layer])\n",
    "    cur_v_heads = torch.tensor(all_last_attn_subvalues[test_layer])\n",
    "    cur_attn_o_split = model.language_model.model.layers[test_layer].self_attn.o_proj.weight.data.T.view(HEAD_NUM, HEAD_DIM, -1)\n",
    "    cur_attn_subvalues_headrecompute = torch.bmm(cur_v_heads, cur_attn_o_split).permute(1, 0, 2)\n",
    "    cur_attn_subvalues_head_sum = torch.sum(cur_attn_subvalues_headrecompute, 0)\n",
    "    cur_layer_input_last = cur_layer_input[-1]\n",
    "    origin_prob = torch.log(get_prob(get_bsvalues(cur_layer_input_last, model, final_var))[predict_index])\n",
    "    cur_attn_subvalues_head_plus = cur_attn_subvalues_head_sum + cur_layer_input_last\n",
    "    cur_attn_plus_probs = torch.log(get_prob(get_bsvalues(\n",
    "            cur_attn_subvalues_head_plus, model, final_var))[:, predict_index])\n",
    "    cur_attn_plus_probs_increase = cur_attn_plus_probs - origin_prob\n",
    "    for i in range(len(cur_attn_plus_probs_increase)):\n",
    "        all_head_increase.append([str(test_layer)+\"_\"+str(i), round(cur_attn_plus_probs_increase[i].item(), 4)])\n",
    "\n",
    "all_head_increase_sort = sorted(all_head_increase, key=lambda x:x[-1])[::-1]\n",
    "# print(all_head_increase_sort[:30])\n",
    "# all_head_increase_list = [x[1] for x in all_head_increase]\n",
    "# all_head_increase_list_split = torch.tensor(all_head_increase_list).view((LAYER_NUM, HEAD_NUM)).permute((1,0)).tolist()\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt_heatmap(all_head_increase_list_split)\n",
    "# plt.savefig(os.path.join(OUTPUT_DIR, \"heatmap.png\"))\n",
    "# plt.close()\n",
    "\n",
    "#pos increase\n",
    "pos_len = len(all_pos_layer_input[0])\n",
    "test_layer, head_index = 22, 27\n",
    "cur_layer_input = torch.tensor(all_pos_layer_input[test_layer])\n",
    "cur_v_heads = torch.tensor(all_last_attn_subvalues[test_layer])\n",
    "cur_attn_o_split = model.language_model.model.layers[test_layer].self_attn.o_proj.weight.data.T.view(HEAD_NUM, HEAD_DIM, -1)\n",
    "cur_attn_subvalues_headrecompute = torch.bmm(cur_v_heads, cur_attn_o_split).permute(1, 0, 2)\n",
    "cur_attn_subvalues_headrecompute_curhead = cur_attn_subvalues_headrecompute[:, head_index, :]\n",
    "cur_layer_input_last = cur_layer_input[-1]\n",
    "origin_prob = torch.log(get_prob(get_bsvalues(\n",
    "    cur_layer_input_last, model, final_var))[predict_index])\n",
    "cur_attn_subvalues_headrecompute_curhead_plus = cur_attn_subvalues_headrecompute_curhead + cur_layer_input_last\n",
    "cur_attn_plus_probs = torch.log(get_prob(get_bsvalues(\n",
    "    cur_attn_subvalues_headrecompute_curhead_plus, model, final_var))[:, predict_index])\n",
    "cur_attn_plus_probs_increase = cur_attn_plus_probs - origin_prob\n",
    "\n",
    "# head_pos_increase = cur_attn_plus_probs_increase.tolist()\n",
    "# head_pos_increase_zip = list(zip(range(pos_len), head_pos_increase))\n",
    "# head_pos_increase_zip_sort = sorted(head_pos_increase_zip, key=lambda x: x[-1])[::-1]\n",
    "# pos_score_sum = sum([x[1] for x in head_pos_increase_zip_sort])\n",
    "\n",
    "# cur_attn_plus_probs_increase_increase_zip = list(zip(range(len(cur_attn_plus_probs_increase)), \n",
    "#     cur_attn_plus_probs_increase.tolist()))\n",
    "# cur_attn_plus_probs_increase_increase_zip_sort = sorted(cur_attn_plus_probs_increase_increase_zip,\n",
    "#     key=lambda x:x[-1])[::-1]\n",
    "# cur_layer_input_bsvalues = get_bsvalues(cur_layer_input, model, final_var)\n",
    "# cur_layer_input_bsvalues_sort = torch.argsort(cur_layer_input_bsvalues, descending=True)\n",
    "# cur_attn_subvalues_headrecompute_curhead_bsvalues = get_bsvalues(\n",
    "#     cur_attn_subvalues_headrecompute_curhead, model, final_var)\n",
    "# cur_attn_subvalues_headrecompute_curhead_bsvalues_sort = torch.argsort(\n",
    "#     cur_attn_subvalues_headrecompute_curhead_bsvalues, descending=True)\n",
    "# key_input = cur_layer_input.clone()\n",
    "# key_input -= torch.tensor(all_pos_layer_input[0])\n",
    "# for layer_i in range(test_layer):\n",
    "#     key_input -= torch.tensor(all_pos_ffn_output[layer_i])\n",
    "# key_input_bsvalues = get_bsvalues(key_input, model, final_var)\n",
    "# key_input_bsvalues_sort = torch.argsort(key_input_bsvalues, descending=True)\n",
    "# value_input = cur_layer_input.clone()\n",
    "# value_input -= torch.tensor(all_pos_layer_input[0])\n",
    "# for layer_i in range(test_layer):\n",
    "#     value_input -= torch.tensor(all_pos_attn_output[layer_i])\n",
    "# value_input_bsvalues = get_bsvalues(value_input, model, final_var)\n",
    "# value_input_bsvalues_sort = torch.argsort(value_input_bsvalues, descending=True)\n",
    "\n",
    "# for pos, increase in cur_attn_plus_probs_increase_increase_zip_sort[:10]:\n",
    "#     print(\"\\n\", pos, \"increase: \", round(increase, 4), \"attn: \", round(\n",
    "#         all_attn_scores[test_layer][0][head_index][-1][pos].item(), 4))\n",
    "#     print(\"layer input: \", [processor.decode(x) for x in cur_layer_input_bsvalues_sort[pos][:20]])\n",
    "#     print(\"key input: \", [processor.decode(x) for x in key_input_bsvalues_sort[pos][:20]])\n",
    "#     print(\"value input: \", [processor.decode(x) for x in value_input_bsvalues_sort[pos][:20]])\n",
    "#     print(\"value ov: \", [processor.decode(x) for x in cur_attn_subvalues_headrecompute_curhead_bsvalues_sort[pos][:10]])\n",
    "\n",
    "test_layer, head_index = all_head_increase_sort[0][0].split(\"_\")\n",
    "test_layer, head_index = int(test_layer), int(head_index)\n",
    "cur_layer_input = outputs[2][test_layer][0][0]\n",
    "cur_v_heads = outputs[2][test_layer][5][0]\n",
    "cur_attn_o_split = model.language_model.model.layers[test_layer].self_attn.o_proj.weight.data.T.view(HEAD_NUM, HEAD_DIM, -1)\n",
    "cur_attn_subvalues_headrecompute = torch.bmm(cur_v_heads, cur_attn_o_split).permute(1, 0, 2)\n",
    "cur_attn_subvalues_headrecompute_curhead = cur_attn_subvalues_headrecompute[:, head_index, :]\n",
    "cur_layer_input_last = cur_layer_input[-1]\n",
    "origin_prob = torch.log(get_prob(get_bsvalues(\n",
    "    cur_layer_input_last, model, final_var))[predict_index])\n",
    "cur_attn_subvalues_headrecompute_curhead_plus = cur_attn_subvalues_headrecompute_curhead + cur_layer_input_last\n",
    "cur_attn_plus_probs = torch.log(get_prob(get_bsvalues(\n",
    "    cur_attn_subvalues_headrecompute_curhead_plus, model, final_var))[:, predict_index])\n",
    "cur_attn_plus_probs_increase = cur_attn_plus_probs - origin_prob\n",
    "head_pos_increase = cur_attn_plus_probs_increase.tolist()\n",
    "curhead_increase_scores = head_pos_increase[5:581]\n",
    "increase_scores_normalize = normalize(curhead_increase_scores)\n",
    "\n",
    "\n",
    "# attn_scores_all = torch.tensor([0.0]*576)\n",
    "# for layer_index in range(LAYER_NUM):\n",
    "#     for head_index in range(HEAD_NUM):\n",
    "#         attn_scores = outputs[2][layer_index][7][0][head_index][-1][5:581]\n",
    "#         attn_scores_all += attn_scores\n",
    "# attn_scores_all = attn_scores_all/1024.0\n",
    "\n",
    "\n",
    "demo_img_h, demo_img_w, demo_img_c = demo_img.shape\n",
    "# demo_img_att = np.array(attn_scores_all.tolist()).reshape((24, 24))\n",
    "# demo_img_att = cv2.resize(demo_img_att,\n",
    "#                         dsize=(demo_img_w, demo_img_h),\n",
    "#                         interpolation=cv2.INTER_CUBIC)\n",
    "demo_img_inc = np.array(increase_scores_normalize).reshape((24, 24))\n",
    "demo_img_inc = cv2.resize(demo_img_inc,\n",
    "                        dsize=(demo_img_w, demo_img_h),\n",
    "                        interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "# plot with matplotlib\n",
    "plt.figure(figsize=(25, 6))\n",
    "\n",
    "# plot target image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(demo_img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"image\")\n",
    "\n",
    "# # plot image with attention masked on it\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow(demo_img)\n",
    "# plt.imshow(demo_img_att, alpha=0.8, cmap=\"gray\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"attention\")\n",
    "\n",
    "# plot image with attention masked on it\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(demo_img)\n",
    "plt.imshow(demo_img_inc, alpha=0.8, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"log increase\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0c0df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEES",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
